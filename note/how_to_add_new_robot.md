./isaaclab.sh --new
# 1.define a roobot
>
>source/isaaclab_assets/isaaclab_assets/robots/cartpole.py

```python
"""Configuration for a simple Cartpole robot."""


import isaaclab.sim as sim_utils
from isaaclab.actuators import ImplicitActuatorCfg
from isaaclab.assets import ArticulationCfg
from isaaclab.utils.assets import ISAACLAB_NUCLEUS_DIR

##
# Configuration
##

CARTPOLE_CFG = ArticulationCfg(
    spawn=sim_utils.UsdFileCfg(
        # 1. 3Dæ¨¡å‹è·¯å¾„ï¼šå» NVIDIA çš„äº‘ç«¯æœåŠ¡å™¨ (Nucleus) ä¸‹è½½ cartpole.usd æ–‡ä»¶
        usd_path=f"{ISAACLAB_NUCLEUS_DIR}/Robots/Classic/Cartpole/cartpole.usd",
        #å¦‚æœä½ æƒ³ç”¨è‡ªå·±æœ¬åœ°é­”æ”¹çš„ USD æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥å†™ç»å¯¹è·¯å¾„ "/home/user/my_robot.usd"ã€‚
        
        # 2. åˆšä½“å±æ€§ï¼šé™åˆ¶æœ€å¤§é€Ÿåº¦ï¼Œé˜²æ­¢ä»¿çœŸç‚¸é£
        rigid_props=sim_utils.RigidBodyPropertiesCfg(
            rigid_body_enabled=True,
            max_linear_velocity=1000.0, # é™åˆ¶æœ€å¤§çº¿é€Ÿåº¦
            enable_gyroscopic_forces=True, # å¼€å¯é™€èºæ•ˆåº”è®¡ç®—ï¼ˆè®©ç‰©ç†æ›´çœŸå®ï¼‰
        ),
        
        # 3. å…³èŠ‚æ±‚è§£å™¨å±æ€§ï¼šç»™ç‰©ç†å¼•æ“çœ‹çš„å‚æ•°
        articulation_props=sim_utils.ArticulationRootPropertiesCfg(
            enabled_self_collisions=False, # æ¯”å¦‚æ†å­ä¼šä¸ä¼šç©¿è¿‡åº•åº§ï¼ŸFalseè¡¨ç¤ºä¸æ£€æµ‹è‡ªç¢°æ’
            solver_position_iteration_count=4, # ç‰©ç†è®¡ç®—ç²¾åº¦ï¼Œé€šå¸¸ 4~8 å¤Ÿç”¨äº†
        ),
    ),
    init_state=ArticulationCfg.InitialStateCfg(
        # pos=(x, y, z): å‡ºç”Ÿåœ¨åŠç©ºä¸­ 2.0 ç±³çš„ä½ç½®ï¼ˆè¿™æ ·å®ƒå¯èƒ½ä¼šæ‰ä¸‹æ¥ç ¸åˆ°åœ°ä¸Šï¼‰
        pos=(0.0, 0.0, 2.0), 
        
        # å…³èŠ‚åˆå§‹è§’åº¦ï¼šæ‰€æœ‰å…³èŠ‚å½’é›¶ï¼Œæ†å­æ˜¯ç›´çš„
        joint_pos={"slider_to_cart": 0.0, "cart_to_pole": 0.0}
    ),
    actuators={
        # --- å°è½¦çš„ç”µæœº (cart_actuator) ---
        "cart_actuator": ImplicitActuatorCfg(
            joint_names_expr=["slider_to_cart"], # æ§åˆ¶å“ªä¸ªå…³èŠ‚ï¼Ÿæ§åˆ¶æ»‘å—
            effort_limit_sim=400.0,              # æœ€å¤§æ¨åŠ›ï¼š400ç‰›
            stiffness=0.0,                       # åˆšåº¦ P gainï¼š0 (åŠ›æ§æ¨¡å¼)
            damping=10.0,                        # é˜»å°¼ D gainï¼š10 (æ¨¡æ‹Ÿæ‘©æ“¦åŠ›/åç”µåŠ¨åŠ¿)
        ),
        
        # --- æ†å­çš„å…³èŠ‚ (pole_actuator) ---
        "pole_actuator": ImplicitActuatorCfg(
            joint_names_expr=["cart_to_pole"],   # æ§åˆ¶å“ªä¸ªå…³èŠ‚ï¼Ÿè¿æ¥æ†å­çš„å…³èŠ‚
            effort_limit_sim=400.0,
            stiffness=0.0, 
            damping=0.0                          # é˜»å°¼æ˜¯ 0ï¼è¿™æ„å‘³ç€è¿™æ˜¯ä¸€ä¸ªã€æ— æ‘©æ“¦æ‘†ã€‘
        ),
    },
)
"""Configuration for a simple Cartpole robot."""
```

# 2.define a env

>/home/oiioaa/Desktop/IsaacLab/source/isaaclab_tasks/isaaclab_tasks/manager_based/classic/cartpole/cartpole_env_cfg.py

## 2.1 dependencies

```python
import math

import isaaclab.sim as sim_utils
from isaaclab.assets import ArticulationCfg, AssetBaseCfg
from isaaclab.envs import ManagerBasedRLEnvCfg
from isaaclab.managers import EventTermCfg as EventTerm
from isaaclab.managers import ObservationGroupCfg as ObsGroup
from isaaclab.managers import ObservationTermCfg as ObsTerm
from isaaclab.managers import RewardTermCfg as RewTerm
from isaaclab.managers import SceneEntityCfg
from isaaclab.managers import TerminationTermCfg as DoneTerm
from isaaclab.scene import InteractiveSceneCfg
from isaaclab.utils import configclass

import isaaclab_tasks.manager_based.classic.cartpole.mdp as mdp

##
# Pre-defined configs
##
from isaaclab_assets.robots.cartpole import CARTPOLE_CFG  # isort:skip


##
# Scene definition
##
```

## 2.2 scene
* InteractiveSceneCfgæ˜¯æ‰€æœ‰ RL ç¯å¢ƒçš„åŸºç±»ï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†åœºæ™¯çš„é‡ç½®ï¼ˆResetï¼‰å’Œå…‹éš†ï¼ˆCloningï¼‰ã€‚
```python
@configclass
class CartpoleSceneCfg(InteractiveSceneCfg):
    """Configuration for a cart-pole scene."""

    # ground plane
    ground = AssetBaseCfg(
        prim_path="/World/ground",
        spawn=sim_utils.GroundPlaneCfg(size=(100.0, 100.0)),
    )

    # cartpole
    # ğŸ‘‡ çœ‹è¿™é‡Œï¼è¿™ä¸ªå˜é‡åå°±å« robot
    robot: ArticulationCfg = CARTPOLE_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")
    #prim_pathåœ¨ Isaac Sim (ä»¥åŠåº•å±‚çš„ USD æ ¼å¼) ä¸­ï¼Œå®ƒçš„æ„æ€å°±æ˜¯ï¼šâ€œè¿™ä¸ªç‰©ä½“åœ¨ 3D ä¸–ç•Œé‡Œçš„ã€ç»å¯¹åœ°å€ã€‘â€ã€‚
    #prim_path="{ENV_REGEX_NS}/Robot"
    '''
    å®é™…è¿è¡Œæ—¶çš„æ ·å­ï¼š
    ç¬¬ 0 å·ç¯å¢ƒï¼š/World/envs/env_0/Robot
    ç¬¬ 1 å·ç¯å¢ƒï¼š/World/envs/env_1/Robot
    ç¬¬ 2 å·ç¯å¢ƒï¼š/World/envs/env_2/Robot
    ...
    ç¬¬ 4095 å·ç¯å¢ƒï¼š/World/envs/env_4095/Robot
    '''

    # lights
    dome_light = AssetBaseCfg(
        prim_path="/World/DomeLight",
        spawn=sim_utils.DomeLightCfg(color=(0.9, 0.9, 0.9), intensity=500.0),
    )
```

## 2.3 action

```python
@configclass
class ActionsCfg:
    """Action specifications for the MDP."""

    joint_effort = mdp.JointEffortActionCfg(asset_name="robot", joint_names=["slider_to_cart"], scale=100.0)
    #AI è¾“å‡ºçš„æ•°å­—ï¼Œè¦è¢«å½“ä½œã€æ¨åŠ›ã€‘(Effort)ï¼Œæ–½åŠ åœ¨å°è½¦çš„ã€æ»‘è½¨å…³èŠ‚ã€‘ä¸Šï¼Œå¹¶ä¸”è¦ã€æ”¾å¤§100å€ã€‘

```

## 2.4 obs(Actor&Critic)

```python
@configclass
class ObservationsCfg:
    """Observation specifications for the MDP."""
    # --- ç»™ Actor çœ‹çš„ (æœ‰é™ä¿¡æ¯) ---
    @configclass
    class PolicyCfg(ObsGroup):
        """Observations for policy group."""

        # observation terms (order preserved)
        joint_pos_rel = ObsTerm(func=mdp.joint_pos_rel)
        #cancelled joint_vel_rel to reduce input size.test lstm performance
        joint_vel_rel = ObsTerm(func=mdp.joint_vel_rel)

        def __post_init__(self) -> None:
            self.enable_corruption = False
            self.concatenate_terms = True

    # observation groups
    policy: PolicyCfg = PolicyCfg()

    # è€å¸ˆå’Œå­¦ç”Ÿçœ‹çš„ä¸€æ ·ï¼Œæ‰€ä»¥çœç•¥ CriticCfg
    '''
    example
    class CriticCfg(ObsGroup):
        sensors = ObsTerm(func=...) # æ— å™ªå£°
        height_map = ObsTerm(func=...) # åœ°å›¾
        ground_friction = ObsTerm(func=...) # æ‘©æ“¦åŠ›
    critic: CriticCfg = CriticCfg()
    '''
```

## 2.5 event(random reset)

```python
@configclass
class EventCfg:
    """Configuration for events."""

    # reset
    reset_cart_position = EventTerm(
        func=mdp.reset_joints_by_offset,
        mode="reset",
        params={
            "asset_cfg": SceneEntityCfg("robot", joint_names=["slider_to_cart"]),
            "position_range": (-1.0, 1.0),
            "velocity_range": (-0.5, 0.5),
        },
    )

    reset_pole_position = EventTerm(
        func=mdp.reset_joints_by_offset,
        mode="reset",
        params={
            "asset_cfg": SceneEntityCfg("robot", joint_names=["cart_to_pole"]),
            "position_range": (-0.25 * math.pi, 0.25 * math.pi),
            "velocity_range": (-0.25 * math.pi, 0.25 * math.pi),
        },
    )
```

## 2.6 reward

```python
@configclass
class RewardsCfg:
    """Reward terms for the MDP."""

    # (1) Constant running reward
    alive = RewTerm(func=mdp.is_alive, weight=1.0)
    # (2) Failure penalty
    terminating = RewTerm(func=mdp.is_terminated, weight=-2.0)
    # (3) Primary task: keep pole upright
    pole_pos = RewTerm(
        func=mdp.joint_pos_target_l2,
        weight=-1.0,
        params={"asset_cfg": SceneEntityCfg("robot", joint_names=["cart_to_pole"]), "target": 0.0},#,<-å˜é‡å (Argument Name) å¿…é¡»å’Œ params é‡Œçš„é”®åï¼ˆKeyï¼‰ä¸€å­—ä¸å·®ã€‚
    )
    # (4) Shaping tasks: lower cart velocity
    cart_vel = RewTerm(
        func=mdp.joint_vel_l1,
        weight=-0.01,
        params={"asset_cfg": SceneEntityCfg("robot", joint_names=["slider_to_cart"])},
    )
    # (5) Shaping tasks: lower pole angular velocity
    pole_vel = RewTerm(
        func=mdp.joint_vel_l1,
        weight=-0.005,
        params={"asset_cfg": SceneEntityCfg("robot", joint_names=["cart_to_pole"])},
    )
```

### 2.6.1 custom reward

* build a private dir(mdp) to writte custom reward

```python
from __future__ import annotations#â€œè¯·å¿½ç•¥æ‰€æœ‰çš„ç±»å‹æç¤ºï¼ˆType Hintsï¼‰ï¼Œä¸è¦åœ¨è¿è¡Œæ—¶å»æ£€æŸ¥å®ƒä»¬å­˜ä¸å­˜åœ¨ã€‚ç•™ç»™ IDE å’Œé™æ€æ£€æŸ¥å·¥å…·å»çœ‹å°±è¡Œäº†ã€‚â€

import torch
from typing import TYPE_CHECKING

from isaaclab.assets import Articulation
from isaaclab.managers import SceneEntityCfg
from isaaclab.utils.math import wrap_to_pi

if TYPE_CHECKING:
    from isaaclab.envs import ManagerBasedRLEnv

                                               #ğŸ‘‡å˜é‡å (Argument Name) å¿…é¡»å’Œ params é‡Œçš„é”®åï¼ˆKeyï¼‰ä¸€å­—ä¸å·®ã€‚
def joint_pos_target_l2(env: ManagerBasedRLEnv, target: float, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    """Penalize joint position deviation from a target value."""
    # extract the used quantities (to enable type-hinting)
    asset: Articulation = env.scene[asset_cfg.name]
    # wrap the joint positions to (-pi, pi)
    joint_pos = wrap_to_pi(asset.data.joint_pos[:, asset_cfg.joint_ids])
    # compute the reward
    return torch.sum(torch.square(joint_pos - target), dim=1)

```

## 2.7 terminate

```python
@configclass
class TerminationsCfg:
    """Termination terms for the MDP."""

    # (1) Time out
    '''
    å«ä¹‰ï¼šå¦‚æœè¿™ä¸€å±€è·‘äº†å¤ªä¹…ï¼ˆæ¯”å¦‚è¶…è¿‡äº† 500 æ­¥ï¼‰ï¼Œå¼ºåˆ¶ç»“æŸã€‚
    func=mdp.time_outï¼šè°ƒç”¨å®˜æ–¹é€šç”¨çš„è®¡æ—¶æ£€æŸ¥å‡½æ•°ã€‚å®ƒä¼šæ£€æŸ¥å½“å‰çš„æ­¥æ•°ï¼ˆepisode lengthï¼‰æ˜¯å¦è¾¾åˆ°äº† max_episodesï¼ˆåœ¨ä¸»è„šæœ¬é‡Œè®¾ç½®ï¼Œæ¯”å¦‚ 500ï¼‰ã€‚
    time_out=Trueï¼šè¿™æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„æ ‡å¿—ä½ï¼
    å®ƒå‘Šè¯‰ç®—æ³•ï¼šâ€œè¿™å±€ç»“æŸä¸æ˜¯å› ä¸ºæœºå™¨äººå¤ªèœï¼ˆè¾“äº†ï¼‰ï¼Œè€Œæ˜¯å› ä¸ºæ²¡æ—¶é—´äº†ã€‚â€
    æ•°å­¦æ„ä¹‰ï¼šåœ¨ç®—å¥–åŠ±ä»·å€¼ï¼ˆValue Functionï¼‰æ—¶ï¼Œè¶…æ—¶ç»“æŸé€šå¸¸ä¸ä¼šæŠŠæœªæ¥çš„é¢„æœŸå¥–åŠ±å½’é›¶ï¼ˆBootstrapï¼‰ï¼Œå› ä¸ºå®ƒå…¶å®è¿˜èƒ½ç»§ç»­æ´»ä¸‹å»ï¼›è€Œå¤±è´¥ç»“æŸï¼ˆæ’å¢™ï¼‰åˆ™ä¼šå½’é›¶ã€‚
    '''
    time_out = DoneTerm(func=mdp.time_out, time_out=True)

    # (2) Cart out of bounds
    cart_out_of_bounds = DoneTerm(
        func=mdp.joint_pos_out_of_manual_limit,
        params={"asset_cfg": SceneEntityCfg("robot", joint_names=["slider_to_cart"]), "bounds": (-3.0, 3.0)},
    )
```

>call back

```python
class RewardsCfg:
    ....
    terminating = RewTerm(func=mdp.is_terminated, weight=-2.0)
    ...
```

* if want multireward

```python
@configclass
class RewardsCfg:
    # ... å…¶ä»–å¥–åŠ±ä¿æŒä¸å˜ ...

    # 1. åˆ é™¤è¿™ä¸ªé€šç”¨çš„ï¼ä¸ç„¶ä¼šé‡å¤æ‰£åˆ†
    # terminating = RewTerm(func=mdp.is_terminated, weight=-2.0) 

    # 2. æ–°å¢ï¼šä¸“é—¨é’ˆå¯¹â€œè½¦å‡ºç•Œâ€çš„ç½šæ¬¾ (é‡ç½š)
    # é€»è¾‘å’Œ TerminationsCfg.cart_out_of_bounds å®Œå…¨ä¸€æ ·
    penalty_cart_out = RewTerm(
        func=mdp.joint_pos_out_of_manual_limit,
        weight=-10.0,  # <--- è¿™é‡Œè®¾ç½®è½¦å‡ºç•Œæ‰£ 10 åˆ†
        params={
            "asset_cfg": SceneEntityCfg("robot", joint_names=["slider_to_cart"]),
            "bounds": (-3.0, 3.0), # å¿…é¡»å’Œ Termination é‡Œçš„èŒƒå›´ä¸€è‡´
        },
    )

    # 3. æ–°å¢ï¼šä¸“é—¨é’ˆå¯¹â€œæ†å­å€’äº†â€çš„ç½šæ¬¾ (è½»ç½š)
    # å‡è®¾ Termination é‡Œä¹Ÿæœ‰ä¸ªç±»ä¼¼çš„ pole_limit
    penalty_pole_drop = RewTerm(
        func=mdp.joint_pos_out_of_manual_limit,
        weight=-5.0,   # <--- è¿™é‡Œè®¾ç½®æ†å­å€’äº†æ‰£ 5 åˆ†
        params={
            "asset_cfg": SceneEntityCfg("robot", joint_names=["cart_to_pole"]),
            "bounds": (-0.25 * math.pi, 0.25 * math.pi),
        },
    )
```

## 2.8 total

```python
@configclass
class CartpoleEnvCfg(ManagerBasedRLEnvCfg):
    """Configuration for the cartpole environment."""

    # Scene settings
    scene: CartpoleSceneCfg = CartpoleSceneCfg(num_envs=4096, env_spacing=4.0, clone_in_fabric=True)
    # Basic settings
    observations: ObservationsCfg = ObservationsCfg()
    actions: ActionsCfg = ActionsCfg()
    events: EventCfg = EventCfg()
    # MDP settings
    rewards: RewardsCfg = RewardsCfg()
    terminations: TerminationsCfg = TerminationsCfg()

    # Post initialization
    def __post_init__(self) -> None:
        """Post initialization."""
        # general settings
        self.decimation = 2
        self.episode_length_s = 5  #ä¸€å±€å¤šé•¿ï¼š5 ç§’ã€‚æ¢ç®—æˆæ­¥æ•°ï¼š5 ç§’ X 60  Hz (æ§åˆ¶é¢‘ç‡) = 300  æ­¥ã€‚
        # viewer settings
        self.viewer.eye = (8.0, 0.0, 5.0)
        # simulation settings
        self.sim.dt = 1 / 120 # ç‰©ç†å¼•æ“çš„è®¡ç®—æ­¥é•¿
        self.sim.render_interval = self.decimation # å†³ç­–é¢‘ç‡å€æ•° (æ¯éš”å‡ æ¬¡ç‰©ç†æ­¥ï¼ŒAI åŠ¨ä¸€æ¬¡è„‘å­)

```

## 2.9 camera

```python
import isaaclab.sim as sim_utils
from isaaclab.managers import ObservationGroupCfg as ObsGroup
from isaaclab.managers import ObservationTermCfg as ObsTerm
from isaaclab.managers import SceneEntityCfg
from isaaclab.sensors import TiledCameraCfg
from isaaclab.utils import configclass

import isaaclab_tasks.manager_based.classic.cartpole.mdp as mdp

from .cartpole_env_cfg import CartpoleEnvCfg, CartpoleSceneCfg
```

### 2.9.1 add camera(RGB&)

```python
@configclass
class CartpoleRGBCameraSceneCfg(CartpoleSceneCfg):

    # add camera to the scene
    #TiledCameraCfg(å¹³é“ºæ¸²æŸ“æŠ€æœ¯)
    tiled_camera: TiledCameraCfg = TiledCameraCfg(
        prim_path="{ENV_REGEX_NS}/Camera",
        offset=TiledCameraCfg.OffsetCfg(pos=(-7.0, 0.0, 3.0), rot=(0.9945, 0.0, 0.1045, 0.0), convention="world"),
        '''
        X = -7.0: æ”¾åœ¨å°è½¦åæ–¹ 7 ç±³å¤„ï¼ˆå‡è®¾è½¦å¤´æœ X æ­£æ–¹å‘ï¼‰ã€‚
        Y = 0.0: å·¦å³å±…ä¸­ã€‚
        Z = 3.0: æ‚¬ç©º 3 ç±³é«˜ã€‚
        è§†è§’æ•ˆæœï¼šè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„ç¬¬ä¸‰äººç§°ä¸Šå¸è§†è§’ (God View)ï¼Œç±»ä¼¼äºç©èµ›è½¦æ¸¸æˆæ—¶çš„é»˜è®¤è§†è§’ã€‚

        (0.9945, ...)
        è¿™æ˜¯ä¸€ä¸ªå››å…ƒæ•°ï¼Œè¡¨ç¤ºç›¸æœºå¾®å¾®å‘ä¸‹ä½å¤´ï¼ˆPitch è½´æ—‹è½¬ï¼‰ï¼Œä»¥ä¾¿ä» 3 ç±³é«˜çš„åœ°æ–¹æ­£å¥½ä¿¯è§†åœ°é¢ä¸Šçš„è½¦ã€‚
        '''
        data_types=["rgb"], #<-
        spawn=sim_utils.PinholeCameraCfg(
            focal_length=24.0, focus_distance=400.0, horizontal_aperture=20.955, clipping_range=(0.1, 20.0)
        ),
        '''
        è¿™å®šä¹‰äº†ç›¸æœºçš„å…‰å­¦å±æ€§ï¼Œå°±åƒä½ ä¹°å•åé•œå¤´æ—¶çœ‹çš„å‚æ•°ã€‚
        focal_length=24.0 (ç„¦è· 24mm):
        è¿™æ˜¯ä¸€ä¸ªå¹¿è§’é•œå¤´ã€‚è§†é‡æ¯”è¾ƒå®½ï¼Œèƒ½çœ‹åˆ°æ›´å¤šçš„ç¯å¢ƒï¼Œä½†è¾¹ç¼˜ä¼šæœ‰ä¸€äº›é€è§†æ‹‰ä¼¸ã€‚
        horizontal_aperture=20.955 (ä¼ æ„Ÿå™¨å®½åº¦):
        é…åˆç„¦è·ï¼Œè¿™å†³å®šäº†ç›¸æœºçš„ è§†åœºè§’ (FOV)ã€‚
        clipping_range=(0.1, 20.0) (è§†è·è£å‰ª):
        è¿‘è£å‰ª (0.1): ç¦»é•œå¤´å°äº 0.1 ç±³çš„ç‰©ä½“ä¸æ¸²æŸ“ï¼ˆé˜²æ­¢ç©¿æ¨¡æŒ¡ä½é•œå¤´ï¼‰ã€‚
        è¿œè£å‰ª (20.0): ç¦»é•œå¤´è¶…è¿‡ 20 ç±³çš„ç‰©ä½“ä¸æ¸²æŸ“ï¼ˆç›´æ¥æ˜¾ç¤ºèƒŒæ™¯è‰²ï¼‰ã€‚è¿™èƒ½æå¤§èŠ‚çœæ˜¾å¡èµ„æºï¼Œåæ­£å¤ªè¿œäº† AI ä¹Ÿçœ‹ä¸æ¸…ã€‚
        '''
        width=100,
        height=100,
    )


@configclass
class CartpoleDepthCameraSceneCfg(CartpoleSceneCfg):

    # add camera to the scene
    tiled_camera: TiledCameraCfg = TiledCameraCfg(
        prim_path="{ENV_REGEX_NS}/Camera",
        offset=TiledCameraCfg.OffsetCfg(pos=(-7.0, 0.0, 3.0), rot=(0.9945, 0.0, 0.1045, 0.0), convention="world"),
        data_types=["distance_to_camera"], #<-
        spawn=sim_utils.PinholeCameraCfg(
            focal_length=24.0, focus_distance=400.0, horizontal_aperture=20.955, clipping_range=(0.1, 20.0)
        ),
        width=100,
        height=100,
    )

```


### 2.9.2 obs

```python
@configclass
class RGBObservationsCfg:
    @configclass
    class RGBCameraPolicyCfg(ObsGroup):
        # 1. å®šä¹‰è¾“å…¥æº
        image = ObsTerm(
            func=mdp.image,  # <-- è¿™æ˜¯ä¸€ä¸ªè·å–åŸå§‹åƒç´ çš„å‡½æ•°
            params={
                "sensor_cfg": SceneEntityCfg("tiled_camera"), # å‘Šè¯‰å®ƒå»è¯»å“ªä¸ªç›¸æœº
                "data_type": "rgb" # å‘Šè¯‰å®ƒè¯»çº¢ç»¿è“ä¸‰ä¸ªé€šé“
            }
        )

        def __post_init__(self):
            self.enable_corruption = False # ä¸åŠ äººä¸ºå™ªå£°(å¦‚åç‚¹)
            self.concatenate_terms = True  # æŠŠæ•°æ®æ‹¼æˆä¸€ä¸ª Tensor

    policy: ObsGroup = RGBCameraPolicyCfg()


@configclass
class DepthObservationsCfg:
    @configclass
    class DepthCameraPolicyCfg(ObsGroup):
        image = ObsTerm(
            func=mdp.image, 
            params={
                "sensor_cfg": SceneEntityCfg("tiled_camera"), 
                "data_type": "distance_to_camera" # <-- å…³é”®åŒºåˆ«ï¼šè¯»å–è·ç¦»
            }
        )

    policy: ObsGroup = DepthCameraPolicyCfg()


@configclass
class ResNet18ObservationCfg:
    @configclass
    class ResNet18FeaturesCameraPolicyCfg(ObsGroup):
        image = ObsTerm(
            func=mdp.image_features, # <-- å…³é”®åŒºåˆ«ï¼šä¸å†å–å›¾ç‰‡ï¼Œè€Œæ˜¯å–ç‰¹å¾
            params={
                "sensor_cfg": SceneEntityCfg("tiled_camera"), 
                "data_type": "rgb", 
                "model_name": "resnet18" # <-- è¯·æ¥äº†å¤–æ´ï¼šResNet18
            },
        )

    policy: ObsGroup = ResNet18FeaturesCameraPolicyCfg()


@configclass
class TheiaTinyObservationCfg:
    @configclass
    class TheiaTinyFeaturesCameraPolicyCfg(ObsGroup):
        image = ObsTerm(
            func=mdp.image_features,
            params={
                "sensor_cfg": SceneEntityCfg("tiled_camera"),
                "data_type": "rgb",
                "model_name": "theia-tiny-patch16-224-cddsv", # <-- è¿™æ˜¯ä¸€ä¸ª Transformer æ¨¡å‹
                "model_device": "cuda:0", # æŒ‡å®šæ¨¡å‹è·‘åœ¨ GPU ä¸Š
            },
        )

    policy: ObsGroup = TheiaTinyFeaturesCameraPolicyCfg()
```

### 2.9.3 env

```python
@configclass
class CartpoleRGBCameraEnvCfg(CartpoleEnvCfg):
    """Configuration for the cartpole environment with RGB camera."""
    
    # 1. åœºæ™¯é…ç½®ï¼šä¸ä»…ä»…æ˜¯æ¢ä¸ªåå­—ï¼Œæ³¨æ„å‚æ•°çš„å˜åŒ–ï¼
    #env_spacing=20å¦‚æœé—´è·åªæœ‰ 4 ç±³ï¼š0å·ç¯å¢ƒçš„ç›¸æœºï¼Œä¼šç›´æ¥æ¶åœ¨ 1å·ç¯å¢ƒçš„å®¶é‡Œï¼ 0å·ç›¸æœºä¼šæ‹åˆ° 1å·å°è½¦çš„å±è‚¡ï¼Œè€Œä¸æ˜¯ 0å·å°è½¦ã€‚æ‰€ä»¥å¿…é¡»æŠŠç¯å¢ƒæ‹‰å¼€åˆ° 20 ç±³è¿œï¼Œä¿è¯æ¯ä¸ªç›¸æœºåªèƒ½çœ‹åˆ°è‡ªå·±å®¶çš„å°è½¦ã€‚
    scene: CartpoleRGBCameraSceneCfg = CartpoleRGBCameraSceneCfg(num_envs=512, env_spacing=20)
    
    # 2. è§‚æµ‹é…ç½®ï¼šæŒ‡å®šç”¨ RGB åƒç´ ä½œä¸ºè¾“å…¥
    observations: RGBObservationsCfg = RGBObservationsCfg()

    def __post_init__(self):
        super().__post_init__()
        # 3. æŠŠåœ°æ¿æ‹†äº†
        self.scene.ground = None
        
        # 4. è°ƒæ•´äººç±»è§‚å¯Ÿè€…çš„è§†è§’
        self.viewer.eye = (7.0, 0.0, 2.5)
        self.viewer.lookat = (0.0, 0.0, 2.5)


@configclass
class CartpoleDepthCameraEnvCfg(CartpoleEnvCfg):
    """Configuration for the cartpole environment with depth camera."""

    scene: CartpoleDepthCameraSceneCfg = CartpoleDepthCameraSceneCfg(num_envs=512, env_spacing=20)

    # åªæ”¹äº†ä¸€è¡Œï¼
    observations: DepthObservationsCfg = DepthObservationsCfg()

    def __post_init__(self):
        super().__post_init__()
        # remove ground as it obstructs the camera
        self.scene.ground = None
        # viewer settings
        self.viewer.eye = (7.0, 0.0, 2.5)
        self.viewer.lookat = (0.0, 0.0, 2.5)


@configclass
class CartpoleResNet18CameraEnvCfg(CartpoleRGBCameraEnvCfg):
    """Configuration for the cartpole environment with ResNet18 features as observations."""
    # åªæ”¹äº†ä¸€è¡Œï¼
    observations: ResNet18ObservationCfg = ResNet18ObservationCfg()


@configclass
class CartpoleTheiaTinyCameraEnvCfg(CartpoleRGBCameraEnvCfg):
    """Configuration for the cartpole environment with Theia-Tiny features as observations."""
    # åªæ”¹äº†ä¸€è¡Œï¼
    observations: TheiaTinyObservationCfg = TheiaTinyObservationCfg()
```

# 3 define Runner
> /home/oiioaa/Desktop/IsaacLab/source/isaaclab_tasks/isaaclab_tasks/manager_based/classic/cartpole/agents/rsl_rl_ppo_cfg.py

```python
from isaaclab.utils import configclass

from isaaclab_rl.rsl_rl import RslRlOnPolicyRunnerCfg, RslRlPpoActorCriticCfg, RslRlPpoAlgorithmCfg, RslRlSymmetryCfg

import isaaclab_tasks.manager_based.classic.cartpole.mdp.symmetry as symmetry
```
## 3.1 RSL_RL

### 3.1.1 MLP

```python
@configclass
class CartpolePPORunnerCfg(RslRlOnPolicyRunnerCfg):
    num_steps_per_env = 16
    max_iterations = 150
    save_interval = 50
    experiment_name = "cartpole"
    empirical_normalization = False
    policy = RslRlPpoActorCriticCfg(
        init_noise_std=1.0,
        actor_hidden_dims=[32, 32],
        critic_hidden_dims=[32, 32],
        activation="elu",
    )
    algorithm = RslRlPpoAlgorithmCfg(
        value_loss_coef=1.0,
        use_clipped_value_loss=True,
        clip_param=0.2,
        entropy_coef=0.005,
        num_learning_epochs=5,
        num_mini_batches=4,
        learning_rate=1.0e-3,
        schedule="adaptive",
        gamma=0.99,
        lam=0.95,
        desired_kl=0.01,
        max_grad_norm=1.0,
    )

```

### 3.1.2 LSTM+MLP

```python
@configclass
class MyLSTMPolicyCfg(RslRlPpoActorCriticCfg):
    rnn_type: str = "lstm"
    rnn_hidden_dim: int = 64
    rnn_num_layers: int = 1
    class_name = "ActorCriticRecurrent"  #care

# Runner é…ç½® 1
@configclass
class CartpolePPORunnerCfg(RslRlOnPolicyRunnerCfg):
    num_steps_per_env = 16
    max_iterations = 150
    save_interval = 50
    experiment_name = "cartpole_lstm"
    empirical_normalization = False

    # ä½¿ç”¨ä½ çš„ LSTM é…ç½®
    policy = MyLSTMPolicyCfg(
        init_noise_std=1.0,
        actor_obs_normalization=False,
        critic_obs_normalization=False,
        actor_hidden_dims=[32, 32],
        critic_hidden_dims=[32, 32],
        activation="elu"
    )
    algorithm = RslRlPpoAlgorithmCfg(
        value_loss_coef=1.0,
        use_clipped_value_loss=True,
        clip_param=0.2,
        entropy_coef=0.005,
        num_learning_epochs=5,
        num_mini_batches=4,
        learning_rate=1.0e-3,
        schedule="adaptive",
        gamma=0.99,
        lam=0.95,
        desired_kl=0.01,
        max_grad_norm=1.0,
    )

# Runner é…ç½® 2
# AI åˆ©ç”¨ç‰©ç†å¯¹ç§°æ€§ï¼Œæ•°æ®ç¿»å€ï¼Œæ”¶æ•›æ›´å¿«ã€‚
@configclass
class CartpolePPORunnerWithSymmetryCfg(CartpolePPORunnerCfg):
    """Configuration for the PPO agent with symmetry augmentation."""

    # all the other settings are inherited from the parent class
    algorithm = RslRlPpoAlgorithmCfg(
        value_loss_coef=1.0,
        use_clipped_value_loss=True,
        clip_param=0.2,
        entropy_coef=0.005,
        num_learning_epochs=5,
        num_mini_batches=4,
        learning_rate=1.0e-3,
        schedule="adaptive",
        gamma=0.99,
        lam=0.95,
        desired_kl=0.01,
        max_grad_norm=1.0,
        symmetry_cfg=RslRlSymmetryCfg(
            use_data_augmentation=True, data_augmentation_func=symmetry.compute_symmetric_states
        ),
    )

```

## 3.2 SKRL

### 3.2.1 seed

```yaml
seed: 24 #manba out
```

### 3.2.2 models

### 3.2.2.1 MLP

```yaml
models:
    separate: False  # æš‚æ—¶å¿½ç•¥ï¼Œæ„æ€æ˜¯ Actor å’Œ Critic å®šä¹‰åœ¨ä¸€èµ·ç®¡ç†
  
    # === ç­–ç•¥ç½‘ç»œ (Actor) ===
    policy:  
        class: GaussianMixin   # ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒæ¨¡å‹ï¼ˆå› ä¸ºè¦åŠ éšæœºå™ªå£°æ¢ç´¢ï¼‰
        
        # ä¸‹é¢è¿™äº› clip_log_std ç­‰ç­‰ï¼Œæ˜¯ç›´æ¥ä¼ ç»™ GaussianMixin __init__ å‡½æ•°çš„å‚æ•°
        # ä½ åœ¨æ–‡æ¡£çš„ GaussianMixin ç±»å‚æ•°é‡Œèƒ½æ‰¾åˆ°å®ƒä»¬
        clip_actions: False
        clip_log_std: True
        min_log_std: -20.0
        max_log_std: 2.0
        initial_log_std: 0.0

        # è¿™é‡Œå¼€å§‹å®šä¹‰ç¥ç»ç½‘ç»œç»“æ„
        network:
        - name: net
            input: OBSERVATIONS  # è¾“å…¥å±‚å¤§å° = ä¼ æ„Ÿå™¨æ•°æ®é•¿åº¦
            layers: [32, 32]     # ä¸­é—´æœ‰ä¸¤ä¸ªéšè—å±‚ï¼Œæ¯å±‚ 32 ä¸ªç¥ç»å…ƒ
            activations: elu     # æ¿€æ´»å‡½æ•°ç”¨ ELU
        output: ACTIONS          # è¾“å‡ºå±‚å¤§å° = æœºå™¨äººå…³èŠ‚æ•°é‡

    # ===  (Critic) ===
    value:
        class: DeterministicMixin
        clip_actions: False
        network:
        - name: net
            input: OBSERVATIONS
            layers: [32, 32]
            activations: elu
        output: ONE
```

| YAML å…³é”®å­— | å«ä¹‰ | å®é™… Python é€»è¾‘ |
| --- | --- | --- |
| **`OBSERVATIONS`** | è§‚æµ‹ç©ºé—´ç»´åº¦ | `env.observation_space.shape[0]` (æ¯”å¦‚ 48) |
| **`ACTIONS`** | åŠ¨ä½œç©ºé—´ç»´åº¦ | `env.action_space.shape[0]` (æ¯”å¦‚ 12) |
| **`ONE`** | æ ‡é‡ (ç”¨äº Critic) | `1` (Critic è¾“å‡ºçš„æ˜¯ä¸€ä¸ªä»·å€¼åˆ†æ•°ï¼Œä¸æ˜¯åŠ¨ä½œå‘é‡) |
| **`STATES`** | å…¨å±€çŠ¶æ€ç»´åº¦ | ç”¨äºéå¯¹ç§° Critic (Teacher)ï¼ŒåŒ…å«ç‰¹æƒä¿¡æ¯ |

#### 3.2.2.2 LSTM + MLP (future)

```yaml
models:
    separate: False  # æš‚æ—¶å¿½ç•¥ï¼Œæ„æ€æ˜¯ Actor å’Œ Critic å®šä¹‰åœ¨ä¸€èµ·ç®¡ç†
  
    # === ç­–ç•¥ç½‘ç»œ (Actor) ===
    policy:  
        class: GaussianMixin   # ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒæ¨¡å‹ï¼ˆå› ä¸ºè¦åŠ éšæœºå™ªå£°æ¢ç´¢ï¼‰
        
        # ä¸‹é¢è¿™äº› clip_log_std ç­‰ç­‰ï¼Œæ˜¯ç›´æ¥ä¼ ç»™ GaussianMixin __init__ å‡½æ•°çš„å‚æ•°
        # ä½ åœ¨æ–‡æ¡£çš„ GaussianMixin ç±»å‚æ•°é‡Œèƒ½æ‰¾åˆ°å®ƒä»¬
        clip_actions: False
        clip_log_std: True
        min_log_std: -20.0
        max_log_std: 2.0
        initial_log_std: 0.0

        # è¿™é‡Œå¼€å§‹å®šä¹‰ç¥ç»ç½‘ç»œç»“æ„
        network:
            # ç¬¬ä¸€å±‚ï¼šLSTM (è®°å¿†æ¨¡å—)
            - name: memory_layer
                input: OBSERVATIONS
                type: LSTM
                num_layers: 1          # LSTM å±‚æ•° å®šä¹‰å±‚æ•°çš„å‚æ•°å« num_layers
                hidden_size: 256   
                
            # ç¬¬äºŒå±‚ï¼šMLP (å†³ç­–/è§£ç æ¨¡å—)
            - name: decision_layer
                type: MLP
                layers: [128, 64]      # MLP è¿™é‡Œä¾ç„¶å« layersï¼Œä¸”å¿…é¡»æ˜¯åˆ—è¡¨
                activations: elu
        output: ACTIONS

    # ===  (Critic) ===
    value:
        class: DeterministicMixin
        clip_actions: False
        network:
        - name: net
            input: OBSERVATIONS
            layers: [32, 32]
            activations: elu
        output: ONE
```

### 3.2.3 memory

```yaml
memory:
  class: RandomMemory
  memory_size: -1  # automatically determined (same as agent:rollouts)
  #â€œç»™æˆ‘å‡†å¤‡ä¸€ä¸ªæ”¯æŒéšæœºå­˜å–çš„ä¸´æ—¶èƒŒåŒ… (RandomMemory)ï¼ŒèƒŒåŒ…çš„å¤§å° (memory_size) åªè¦åˆšå¥½èƒ½è£…ä¸‹ Agent è¿™ä¸€è½®é‡‡é›†çš„æ•°æ® (-1) å°±è¡Œäº†ã€‚åæ­£å­¦å®Œè¿™ä¸€è½®å°±è¦å€’æ‰çš„ã€‚â€
```

### 3.2.4 agent

#### 3.2.4.1 PPO

```yaml
# PPO agent configuration
# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html

agent:
  # 1. ç®—æ³•æ ¸å¿ƒç±»
  class: PPO  

  # 2. é‡‡æ ·ä¸å­¦ä¹ èŠ‚å¥ (The Loop)
  # å«ä¹‰ï¼šæ¯æ¬¡æ›´æ–°ç½‘ç»œå‰ï¼Œæ¯ä¸ªç¯å¢ƒå…ˆç©å‡ æ­¥ï¼Ÿ
  # è®¡ç®—ï¼šå¦‚æœ num_envs=4096, rollouts=16ï¼Œé‚£æ€»æ•°æ®é‡ = 65,536 æ­¥
  # å»ºè®®ï¼šä¿æŒ 16~24ï¼Œè¿™æ˜¯ Isaac Lab çš„ç»éªŒå€¼
  rollouts: 16

  # å«ä¹‰ï¼šæ‹¿åˆ°çš„è¿™æ‰¹ 65,536 æ¡æ•°æ®ï¼Œè¦åå¤å¤ä¹ å‡ éï¼Ÿ
  # å»ºè®®ï¼š5~8 éã€‚å¤ªå°‘å­¦ä¸ä¼šï¼Œå¤ªå¤šä¼šè¿‡æ‹Ÿåˆï¼ˆé’»ç‰›è§’å°–ï¼‰
  learning_epochs: 8

  # å«ä¹‰ï¼šä¸€å£æ°”åƒä¸ä¸‹ 6ä¸‡æ¡æ•°æ®ï¼Œåˆ‡æˆå‡ å—å–‚ç»™æ˜¾å¡ï¼Ÿ
  # å»ºè®®ï¼š4 æˆ– 8ã€‚åˆ‡å¾—è¶Šç»†ï¼Œæ˜¾å­˜å ç”¨è¶Šä½
  mini_batches: 8

  # 3. è¿œè§ä¸æƒè¡¡ (RL Hyperparameters)
  # å«ä¹‰ï¼šæŠ˜æ‰£å› å­ (Gamma)ã€‚ä»£è¡¨ AI æœ‰å¤šåœ¨ä¹â€œæœªæ¥â€çš„å¥–åŠ±ã€‚
  # 0.99 = å¾ˆæœ‰è¿œè§ï¼›0.5 = é¼ ç›®å¯¸å…‰ã€‚
  # å»ºè®®ï¼šæœºå™¨äººä»»åŠ¡é€šå¸¸ç”¨ 0.99
  discount_factor: 0.99

  # å«ä¹‰ï¼šGAE å‚æ•° (Lambda)ã€‚ç”¨äºå¹³è¡¡æ–¹å·®å’Œåå·®ã€‚
  # å»ºè®®ï¼š0.95 æ˜¯ RL ç•Œçš„é»„é‡‘æ ‡å‡†ï¼Œåˆ«åŠ¨å®ƒ
  lambda: 0.95

  # 4. å­¦ä¹ é€Ÿåº¦ (Optimization)
  # å«ä¹‰ï¼šå­¦ä¹ ç‡ (Learning Rate)ã€‚æ­¥å­è¿ˆå¤šå¤§ã€‚
  # å»ºè®®ï¼š3e-4 (0.0003) æ˜¯æœ€å¸¸ç”¨çš„èµ·å§‹å€¼
  learning_rate: 3.0e-04

  # å«ä¹‰ï¼šå­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚è¿™åœ¨ Isaac Gym/Lab é‡Œéå¸¸é‡è¦ï¼
  # ä½œç”¨ï¼šå®ƒä¼šæ ¹æ® KL æ•£åº¦ï¼ˆç­–ç•¥å˜åŒ–çš„å‰§çƒˆç¨‹åº¦ï¼‰è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡
  learning_rate_scheduler: KLAdaptiveLR

  # å«ä¹‰ï¼šKL æ•£åº¦çš„é˜ˆå€¼ã€‚
  # é€»è¾‘ï¼šå¦‚æœç­–ç•¥å˜åŒ–è¶…è¿‡ 0.008ï¼Œè¯´æ˜æ­¥å­å¤ªå¤§äº†ï¼Œå­¦ä¹ ç‡ä¼šè‡ªåŠ¨å‡åŠã€‚
  # å»ºè®®ï¼š0.008 ~ 0.01 éƒ½æ˜¯åˆç†èŒƒå›´
  learning_rate_scheduler_kwargs:
    kl_threshold: 0.008

  # 5. æ•°æ®é¢„å¤„ç† (Preprocessing) â€”â€” âš ï¸ ä½ çš„è®ºæ–‡å¤ç°å…³é”®ç‚¹ï¼
  # å«ä¹‰ï¼šçŠ¶æ€å½’ä¸€åŒ–ã€‚æŠŠä¼ æ„Ÿå™¨æ•°æ®ï¼ˆå¦‚é«˜åº¦ 0.3, é€Ÿåº¦ 20.0ï¼‰ç¼©æ”¾åˆ°æ ‡å‡†æ­£æ€åˆ†å¸ƒ
  # ğŸ”´ ç°çŠ¶ï¼šnull (å…³é—­)ã€‚è¿™å¯¹äºå››è¶³æœºå™¨äººæ˜¯ âŒ é”™è¯¯çš„ï¼
  # âœ… ä¿®æ”¹ï¼šå¿…é¡»æ”¹æˆ RunningStandardScalerï¼Œå¦åˆ™å¾ˆéš¾æ”¶æ•›
  state_preprocessor: null
  state_preprocessor_kwargs: null

  # å«ä¹‰ï¼šä»·å€¼å½’ä¸€åŒ–ã€‚æŠŠ Critic é¢„æµ‹çš„åˆ†æ•°ä¹Ÿå½’ä¸€åŒ–
  # å»ºè®®ï¼šé€šå¸¸ä¹Ÿå¼€å¯ RunningStandardScaler
  value_preprocessor: null
  value_preprocessor_kwargs: null

  # 6. è®­ç»ƒç¨³å®šæ€§ (Clipping & Safety)
  # å«ä¹‰ï¼šéšæœºæ¢ç´¢æ­¥æ•°ã€‚PPO æ˜¯ On-Policy çš„ï¼Œè¿™é‡Œé€šå¸¸è®¾ä¸º 0
  random_timesteps: 0
  learning_starts: 0

  # å«ä¹‰ï¼šæ¢¯åº¦è£å‰ªã€‚é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼ˆæ›´æ–°å¹…åº¦è¿‡å¤§å¯¼è‡´æ•°å€¼æº¢å‡ºï¼‰
  grad_norm_clip: 1.0

  # å«ä¹‰ï¼šPPO æ ¸å¿ƒå‚æ•°ã€‚é™åˆ¶æ–°æ—§ç­–ç•¥çš„å·®å¼‚ä¸èƒ½è¶…è¿‡ 20%
  # å»ºè®®ï¼š0.2 æ˜¯æ ‡å‡†å€¼ï¼Œåˆ«åŠ¨
  ratio_clip: 0.2

  # å«ä¹‰ï¼šé™åˆ¶ Critic å¯¹ä»·å€¼é¢„æµ‹çš„æ›´æ–°å¹…åº¦
  value_clip: 0.2
  clip_predicted_values: True

  # 7. å¥–åŠ±ä¸æ¢ç´¢ (Rewards)
  # å«ä¹‰ï¼šç†µå¥–åŠ±ç³»æ•°ã€‚é¼“åŠ± AI â€œå¤šå°è¯•ä¸åŒåŠ¨ä½œâ€
  # å»ºè®®ï¼šAMP ä»»åŠ¡é€šå¸¸è®¾ä¸º 0.0 æˆ–æå°å€¼ (0.001)ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›åŠ¨ä½œåƒçœŸç‹—ä¸€æ ·ç¨³å®šï¼Œä¸è¦çæ™ƒ
  entropy_loss_scale: 0.0

  # å«ä¹‰ï¼šä»·å€¼æŸå¤±çš„æƒé‡ã€‚Critic è®­ç»ƒçš„é‡è¦æ€§
  value_loss_scale: 2.0

  # å«ä¹‰ï¼šKL æ•£åº¦ç›®æ ‡ã€‚å¦‚æœè®¾äº† schedulerï¼Œè¿™ä¸ªå¯ä»¥è®¾ä¸º 0
  kl_threshold: 0.0

  # å«ä¹‰ï¼šå¥–åŠ±ç¼©æ”¾ã€‚æŠŠæ‰€æœ‰å¥–åŠ±ä¹˜ä»¥ 1.0 (æ²¡å˜)
  # æœ‰æ—¶å€™ä¸ºäº†æ•°å€¼ç¨³å®šï¼Œä¼šç¼©æ”¾åˆ° 0.1 æˆ– 0.01
  rewards_shaper_scale: 1.0

  # å«ä¹‰ï¼šè¶…æ—¶å¤„ç†ã€‚
  # True = è¶…æ—¶è¢«è§†ä¸ºâ€œä»»åŠ¡æ²¡å®Œæˆä½†æ²¡æ­»â€ (Bootstrap)
  # False = è¶…æ—¶è¢«è§†ä¸ºâ€œä»»åŠ¡ç»“æŸâ€
  # å»ºè®®ï¼šå¯¹äºæ— é™æ—¶é—´ä»»åŠ¡ï¼ˆèµ°è·¯ï¼‰ï¼Œé€šå¸¸è®¾ä¸º True æˆ– False å½±å“ä¸å¤§ï¼ŒIsaac Lab é»˜è®¤ False
  time_limit_bootstrap: False

  # 8. å®éªŒè®°å½• (Logging)
  experiment:
    directory: "cartpole"       # æ—¥å¿—å­˜å“ªï¼Ÿ
    experiment_name: ""         # å®éªŒåå«å•¥ï¼Ÿ
    write_interval: auto        # å¤šä¹…å†™ä¸€æ¬¡ Tensorboard
    checkpoint_interval: auto   # å¤šä¹…å­˜ä¸€æ¬¡æ¨¡å‹ (.pt æ–‡ä»¶)
```

### 3.2.4 trainer

```yaml
trainer:
  class: SequentialTrainer
  timesteps: 2400 #æ„æ€æ˜¯ï¼šâ€œå¾ªç¯è·‘ 2400 æ­¥å°±åœä¸‹æ¥â€ã€‚
  environment_info: log
```

# 4 register
> source/isaaclab_tasks/isaaclab_tasks/manager_based/classic/cartpole/__init__.py
## 4.1
```python
gym.register(
    id="Isaac-Cartpole-v0",
    entry_point="isaaclab.envs:ManagerBasedRLEnv",

    # 3. å…³é—­æ£€æŸ¥ (Disable Checker)
    # å¿…é¡»è®¾ä¸º Trueã€‚å› ä¸º Isaac Lab æ˜¯ GPU å¹¶è¡Œç¯å¢ƒï¼Œ
    # ä¸ç¬¦åˆä¼ ç»Ÿ Gym å¯¹ CPU ç¯å¢ƒçš„ä¸¥æ ¼æ ¼å¼æ£€æŸ¥ã€‚
    disable_env_checker=True,

    # 4. æ ¸å¿ƒå‚æ•° (kwargs)
    # è¿™é‡Œæ˜¯ä¼ é€’ç»™ "æ ¸å¿ƒå¼•æ“" çš„å…·ä½“è®¾ç½®
    kwargs={
        # ====================================================
        # A. ç¯å¢ƒé…ç½® (ç‰©ç†ä¸–ç•Œ)
        # ----------------------------------------------------
        # æŒ‡å‘ä½ çš„ç¯å¢ƒé…ç½®ç±» (EnvCfg)ã€‚
        # å†³å®šäº†ï¼šæœºå™¨äººé•¿å•¥æ ·ã€é‡åŠ›å¤šå°‘ã€è§‚æµ‹ä»€ä¹ˆæ•°æ®ã€å¥–åŠ±æ€ä¹ˆç®—ã€‚
        # æ ¼å¼ï¼š"{æ¨¡å—è·¯å¾„}:{ç±»å}"
        "env_cfg_entry_point": f"{__name__}.cartpole_env_cfg:CartpoleEnvCfg",

        # ====================================================
        # B. ç®—æ³•é…ç½® (å¤§è„‘è®­ç»ƒ)
        # ----------------------------------------------------
        # æŒ‡å‘ RSL-RL çš„è®­ç»ƒå‚æ•°é…ç½®ç±» (RunnerCfg)ã€‚
        # å†³å®šäº†ï¼šå­¦ä¹ ç‡(lr)ã€æ‰¹æ¬¡å¤§å°(batch_size)ã€PPO å‚æ•°ç­‰ã€‚
        # å¦‚æœä½ åªç”¨ rsl_rlï¼Œå†™è¿™ä¸€è¡Œå°±è¶³å¤Ÿäº†ï¼å…¶ä»–çš„ sb3, skrl éƒ½å¯ä»¥åˆ æ‰ã€‚
        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:CartpolePPORunnerCfg",

        # "rl_games_cfg_entry_point": f"{agents.__name__}:rl_games_ppo_cfg.yaml",
        # "rsl_rl_with_symmetry_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:CartpolePPORunnerWithSymmetryCfg",
        # "skrl_cfg_entry_point": f"{agents.__name__}:skrl_ppo_cfg.yaml",
        # "sb3_cfg_entry_point": f"{agents.__name__}:sb3_ppo_cfg.yaml",
    },
)
```